{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### T9 predictive text\n",
    "\n",
    "No, T9 doesn't guess character by character — that's the key insight that made it clever. It works at the **word level**, not the character level.\n",
    "\n",
    "When you press a sequence of digits, T9 waits until it has enough context and then looks up all possible words that match the entire digit sequence at once. So pressing `4-3` doesn't first guess `g/h/i` then `d/e/f` — it just finds all words whose letters map to `4` then `3`, which gives you `he`, `if`, `id`, `ge` etc., and surfaces the most frequent one.\n",
    "\n",
    "**How frequency ranking works in practice:**\n",
    "\n",
    "The phone ships with a static dictionary where each word has a pre-assigned frequency score based on general English usage. The highest frequency match for the digit sequence is shown first. So for `4663` it knows `good` is more common than `gone` or `home` and shows that by default.\n",
    "\n",
    "Over time many T9 implementations also did **personal learning** — if you repeatedly selected `gone` over `good` for `4663`, it would bump `gone`'s personal frequency score and start showing it first for you.\n",
    "\n",
    "**The user experience flow:**\n",
    "\n",
    "1. You press `4663`\n",
    "2. T9 looks up all words matching that sequence and sorts by frequency\n",
    "3. It displays the top match, say `good`\n",
    "4. If that's wrong you press `0` or `*` to cycle through alternatives: `gone`, `home`\n",
    "5. You confirm with a space or punctuation\n",
    "\n",
    "**Where it gets interesting** is ambiguous short sequences like `43` which could be `he`, `if`, `id`, `ge` — frequency scoring is what makes it not feel like a guessing game. And for words not in the dictionary, there was usually a fallback \"multi-tap\" mode where pressing `4` twice gives you `h`, three times gives `i` — the old pre-T9 method.\n",
    "\n",
    "So the trie implementation above is actually a reasonable model of the core lookup, but a real T9 would attach a frequency score to each `is_end` node and sort results by that rather than returning an unordered list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blog\n",
    "class TrieNode:\n",
    "    def __init__(self, value: str, parent: \"TrieNode | None\" = None):\n",
    "        self._children: dict[str, TrieNode] = {}\n",
    "        self._insertion_count = 0\n",
    "        self._value = value\n",
    "        self._parent = parent\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"TrieNode<{self._value}>\"  # pragma: no cover\n",
    "\n",
    "    @cached_property\n",
    "    def word(self) -> str:\n",
    "        return \"\".join(n._value for n in self._bottom_up_traversal())[::-1]\n",
    "\n",
    "    def _bottom_up_traversal(self) -> Iterable[\"TrieNode\"]:\n",
    "        current: \"TrieNode | None\" = self\n",
    "        while current is not None:\n",
    "            yield current\n",
    "            current = current._parent\n",
    "\n",
    "    @property\n",
    "    def word_nodes(self) -> Iterable[\"TrieNode\"]:\n",
    "        result = []\n",
    "        dfs = [self]\n",
    "        while dfs:\n",
    "            node = dfs.pop()\n",
    "            if node._insertion_count:\n",
    "                result.append(node)\n",
    "\n",
    "            for child in node._children.values():\n",
    "                dfs.append(child)\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claud\n",
    "\n",
    "T9_MAP = {\n",
    "    '2': 'abc',\n",
    "    '3': 'def',\n",
    "    '4': 'ghi',\n",
    "    '5': 'jkl',\n",
    "    '6': 'mno',\n",
    "    '7': 'pqrs',\n",
    "    '8': 'tuv',\n",
    "    '9': 'wxyz'\n",
    "}\n",
    "\n",
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.children = {}\n",
    "        self.is_end = False\n",
    "\n",
    "class T9:\n",
    "    def __init__(self):\n",
    "        self.root = TrieNode()\n",
    "\n",
    "    def insert(self, word: str) -> None:\n",
    "        node = self.root\n",
    "        for char in word:\n",
    "            if char not in node.children:\n",
    "                node.children[char] = TrieNode()\n",
    "            node = node.children[char]\n",
    "        node.is_end = True\n",
    "\n",
    "    def predict(self, digits: str) -> list[str]:\n",
    "        results = []\n",
    "        self._dfs(self.root, digits, 0, \"\", results)\n",
    "        return results\n",
    "\n",
    "    def _dfs(self, node: TrieNode, digits: str, depth: int, current: str, results: list) -> None:\n",
    "        # Collected a full match for the digit sequence\n",
    "        if depth == len(digits):\n",
    "            if node.is_end:\n",
    "                results.append(current)\n",
    "            return\n",
    "\n",
    "        # Try every letter mapped to the current digit\n",
    "        for char in T9_MAP[digits[depth]]:\n",
    "            if char in node.children:\n",
    "                self._dfs(node.children[char], digits, depth + 1, current + char, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t9 = T9()\n",
    "\n",
    "words = [\"the\", \"of\", \"and\", \"he\", \"she\", \"his\", \"her\", \"home\", \"good\", \"gone\"]\n",
    "for word in words:\n",
    "    t9.insert(word)\n",
    "\n",
    "print(t9.predict(\"4663\"))   # ['gone', 'good', 'home']\n",
    "print(t9.predict(\"843\"))    # ['the']\n",
    "print(t9.predict(\"43\"))     # ['he'] — 'he' = 4→h, 3→e\n",
    "print(t9.predict(\"743\"))    # ['she'] — 'she' = 7→s, 4→h, 3→e\n",
    "print(t9.predict(\"447\"))    # ['his'] — 'his' = 4→h, 4→i, 7→s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
